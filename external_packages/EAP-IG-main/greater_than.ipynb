{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Greater-Than Circuit Using EAP(-IG)\n",
    "\n",
    "First, we import various packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import PreTrainedTokenizer\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "from eap.graph import Graph\n",
    "from eap.evaluate import evaluate_graph, evaluate_baseline\n",
    "from eap.attribute import attribute "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Metrics\n",
    "\n",
    "This package expects data to come from a dataloader. Each item consists of clean and corrupted paired inputs (strings), as well as a label (encoded as a token id). For convenience, we've included a dataset in that form as a CSV (more to come with the full code of the paper).\n",
    "\n",
    "A metric takes in the model's (possibly corrupted) logits, clean logits, input lengths, and labels. It computes a metric value for each batch item; this can either be used as is, or turned into a loss (lower is better), or meaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_EAP(xs):\n",
    "    clean, corrupted, labels = zip(*xs)\n",
    "    clean = list(clean)\n",
    "    corrupted = list(corrupted)\n",
    "    return clean, corrupted, labels\n",
    "\n",
    "class EAPDataset(Dataset):\n",
    "    def __init__(self, filepath):\n",
    "        self.df = pd.read_csv(filepath)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def shuffle(self):\n",
    "        self.df = self.df.sample(frac=1)\n",
    "\n",
    "    def head(self, n: int):\n",
    "        self.df = self.df.head(n)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        return row['clean'], row['corrupted'], row['label']\n",
    "    \n",
    "    def to_dataloader(self, batch_size: int):\n",
    "        return DataLoader(self, batch_size=batch_size, collate_fn=collate_EAP)\n",
    "    \n",
    "def get_logit_positions(logits: torch.Tensor, input_length: torch.Tensor):\n",
    "    batch_size = logits.size(0)\n",
    "    idx = torch.arange(batch_size, device=logits.device)\n",
    "\n",
    "    logits = logits[idx, input_length - 1]\n",
    "    return logits\n",
    "\n",
    "def get_prob_diff(tokenizer: PreTrainedTokenizer):\n",
    "    year_indices = torch.tensor([tokenizer(f'{year:02d}').input_ids[0] for year in range(100)])\n",
    "\n",
    "    def prob_diff(logits: torch.Tensor, clean_logits: torch.Tensor, input_length: torch.Tensor, labels: torch.Tensor, mean=True, loss=False):\n",
    "        logits = get_logit_positions(logits, input_length)\n",
    "        probs = torch.softmax(logits, dim=-1)[:, year_indices]\n",
    "\n",
    "        results = []\n",
    "        for prob, year in zip(probs, labels):\n",
    "            results.append(prob[year + 1 :].sum() - prob[: year + 1].sum())\n",
    "    \n",
    "        results = torch.stack(results)\n",
    "        if loss:\n",
    "            results = -results\n",
    "        if mean: \n",
    "            results = results.mean()\n",
    "        return results\n",
    "    return prob_diff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing EAP-IG\n",
    "\n",
    "First, we load the model, data, and metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model_name = 'gpt2-small'\n",
    "model = HookedTransformer.from_pretrained(model_name, device='cuda')\n",
    "model.cfg.use_split_qkv_input = True\n",
    "model.cfg.use_attn_result = True\n",
    "model.cfg.use_hook_mlp_in = True\n",
    "\n",
    "ds = EAPDataset('greater_than_data.csv')\n",
    "dataloader = ds.to_dataloader(120)\n",
    "prob_diff = get_prob_diff(model.tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we perform EAP! We instantiate an unscored graph from the model, and use the attribute method to score it. This requires a model, graph, dataloader, and loss. We set `method='EAP-IG'`, and set the number of iterations via `ig_steps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next tokens predicted: 59, 45, 60, 90, 90, 92, 50, 60, 90, 40, 50, 20, 49, 50, 50, 85, 50, 65, 10, 50, 10, 60, 65, 29, 70, 50, 40, 65, 20, 89, 20, 22, 64, 20, 75, 98, 50, 90, 50, 10, 90, 45, 94, 65, 40, 20, 10, 62, 50, 30, 96, 50, 18, 45, 60, 70, 90, 75, 90, 75, 14, 30, 50, 60, 98, 50, 90, 20, 60, 90, 94, 13, 83, 90, 50, 50, 99, 50, 10, 90, 59, 94, 90, 60, 50, 90, 30, 10, 70, 70, 92, 85, 90, 20, 90, 50, 20, 50, 04, 20, 42, 90, 94, 60, 70, 40, 92, 14, 45, 44, 42, 99, 40, 70, 75, 90, 50, 20, 60, 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:04<00:34,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next tokens predicted: 50, 60, 50, 50, 78, 90, 60, 70, 60, 70, 50, 60, 82, 94, 10, 60, 65, 95, 95, 90, 90, 60, 90, 90, 25, 90, 45, 65, 90, 72, 10, 60, 50, 04, 29, 50, 60, 90, 60, 30, 40, 45, 75, 60, 50, 28, 60, 10, 60, 99, 42, 62, 85, 98, 40, 90, 45, 55, 90, 50, 90, 64, 90, 20, 50, 50, 20, 20, 60, 09, 10, 40, 90, 60, 90, 10, 90, 60, 83, 60, 90, 85, 60, 85, 75, 20, 50, 25, 10, 50, 20, 90, 60, 20, 30, 20, 50, 30, 50, 65, 50, 60, 40, 50, 50, 42, 98, 44, 90, 40, 50, 90, 50, 90, 42, 60, 42, 80, 10, 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:05<00:45,  5.65s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m g = Graph.from_model(model)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Attribute using the model, graph, clean / corrupted data and labels, as well as a metric\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mattribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprob_diff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mEAP-IG-inputs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mig_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mech-interp-ft/.venv/lib/python3.12/site-packages/eap/attribute.py:444\u001b[39m, in \u001b[36mattribute\u001b[39m\u001b[34m(model, graph, dataloader, metric, method, intervention, aggregation, ig_steps, intervention_dataloader, quiet)\u001b[39m\n\u001b[32m    442\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m intervention != \u001b[33m'\u001b[39m\u001b[33mpatching\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    443\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mintervention must be \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpatching\u001b[39m\u001b[33m'\u001b[39m\u001b[33m for EAP-IG-inputs, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mintervention\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m444\u001b[39m     scores = \u001b[43mget_scores_eap_ig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mig_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m'\u001b[39m\u001b[33mclean-corrupted\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    446\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m intervention != \u001b[33m'\u001b[39m\u001b[33mpatching\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mech-interp-ft/.venv/lib/python3.12/site-packages/eap/attribute.py:166\u001b[39m, in \u001b[36mget_scores_eap_ig\u001b[39m\u001b[34m(model, graph, dataloader, metric, steps, quiet)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m model.hooks(fwd_hooks=[(graph.nodes[\u001b[33m'\u001b[39m\u001b[33minput\u001b[39m\u001b[33m'\u001b[39m].out_hook, input_interpolation_hook(step))], bwd_hooks=bwd_hooks):\n\u001b[32m    165\u001b[39m     logits = model(clean_tokens, attention_mask=attention_mask)\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     metric_value = \u001b[43mmetric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch.isnan(metric_value).any().item():\n\u001b[32m    168\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMetric value is NaN\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mget_prob_diff.<locals>.prob_diff\u001b[39m\u001b[34m(logits, clean_logits, input_length, labels, mean, loss)\u001b[39m\n\u001b[32m     41\u001b[39m results = []\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m prob, year \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(probs, labels):\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     results.append(prob[year + \u001b[32m1\u001b[39m :].sum() - \u001b[43mprob\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43myear\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     45\u001b[39m results = torch.stack(results)\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loss:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Instantiate a graph with a model\n",
    "g = Graph.from_model(model)\n",
    "\n",
    "# Attribute using the model, graph, clean / corrupted data and labels, as well as a metric\n",
    "attribute(model, g, dataloader, partial(prob_diff, loss=True, mean=True), method='EAP-IG-inputs', ig_steps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply greedy search to the scored graph to find a circuit! We prune dead nodes, and export the circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.apply_topn(200, True)\n",
    "g.to_json('graph.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then convert our circuit into a visualization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pygraphviz\n",
    "    gz = g.to_image(f'graph.png')\n",
    "except ImportError:\n",
    "    print(\"No pygraphviz installed; skipping this part\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then evaluate our model's metric score as opposed to a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:05<00:00,  1.59it/s]\n",
      "100%|██████████| 9/9 [00:06<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original performance was 0.8143222332000732; the circuit's performance is 0.7449120283126831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "baseline = evaluate_baseline(model, dataloader, partial(prob_diff, loss=False, mean=False)).mean().item()\n",
    "results = evaluate_graph(model, g, dataloader, partial(prob_diff, loss=False, mean=False)).mean().item()\n",
    "print(f\"Original performance was {baseline}; the circuit's performance is {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 150)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.count_included_nodes(), g.count_included_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compare that to a circuit found with vanilla EAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:16<00:00,  1.84s/it]\n",
      "100%|██████████| 9/9 [00:06<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original performance was 0.8143222332000732; the circuit's performance is 0.656327486038208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a graph with a model\n",
    "g_eap = Graph.from_model(model)\n",
    "\n",
    "# Attribute using the model, graph, clean / corrupted data and labels, as well as a metric\n",
    "attribute(model, g_eap, dataloader, partial(prob_diff, loss=True, mean=True), method='EAP')\n",
    "\n",
    "g_eap.apply_topn(200, True)\n",
    "\n",
    "results_eap = evaluate_graph(model, g_eap, dataloader, partial(prob_diff, loss=False, mean=False)).mean().item()\n",
    "print(f\"Original performance was {baseline}; the circuit's performance is {results_eap}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also test other EAP-IG variants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:27<00:00,  3.06s/it]\n",
      "100%|██████████| 9/9 [00:06<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original performance was 0.8143222332000732; the circuit's performance is 0.6857951879501343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a graph with a model\n",
    "g_cc = Graph.from_model(model)\n",
    "\n",
    "# Attribute using the model, graph, clean / corrupted data and labels, as well as a metric\n",
    "attribute(model, g_cc, dataloader, partial(prob_diff, loss=True, mean=True), method='clean-corrupted')\n",
    "\n",
    "g_cc.apply_topn(200, True)\n",
    "\n",
    "results_cc = evaluate_graph(model, g_cc, dataloader, partial(prob_diff, loss=False, mean=False)).mean().item()\n",
    "print(f\"Original performance was {baseline}; the circuit's performance is {results_cc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
