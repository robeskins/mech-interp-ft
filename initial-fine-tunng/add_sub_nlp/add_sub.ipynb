{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be56a3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_prompt_templates = [\n",
    "#     lambda n1, n2: f'What is {n1} plus {n2}?',\n",
    "#     lambda n1, n2: f'What is the sum of {n1} and {n2}?',\n",
    "#     lambda n1, n2: f'{n1}+{n2}=',\n",
    "#     lambda n1, n2: f'Combien font {n1} plus {n2}?',\n",
    "#     lambda n1, n2: f'What is {n1} times {n2}',\n",
    "#     lambda n1, n2: f'{n1}âŠ•{n2}=',\n",
    "# ]\n",
    "\n",
    "correct_prompt_templates = [\n",
    "    lambda n1, n2: f'What is {n1} plus {n2}?',\n",
    "    lambda n1, n2: f'{n1}+{n2}=',\n",
    "]\n",
    "\n",
    "prefix_prompt = 'Solve the following and respond with only the final answer:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e9d0fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "number_examples_train = 6000\n",
    "number_examples_test = 500\n",
    "\n",
    "results_train = []\n",
    "results_test = []\n",
    "\n",
    "seen = set()\n",
    "\n",
    "def make_key(prompt, corrupted, answer):\n",
    "    return (prompt, corrupted, answer)\n",
    "\n",
    "for j, template in enumerate(correct_prompt_templates):\n",
    "    i = 0\n",
    "    while i < number_examples_train:\n",
    "        a = random.randint(10, 99)\n",
    "        b = random.randint(10, 99)\n",
    "        c = random.randint(10, 99)\n",
    "        answer = a + b\n",
    "\n",
    "        prompt = template(a, b)\n",
    "        corrupted_prompt = template(a, c)\n",
    "        full_prompt = prefix_prompt + ' ' + prompt\n",
    "        full_corrupted = prefix_prompt + ' ' + corrupted_prompt\n",
    "\n",
    "        key = make_key(full_prompt, full_corrupted, answer)\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "\n",
    "        results_train.append({\n",
    "            'id': j,\n",
    "            'prompt': full_prompt,\n",
    "            'answer': answer,\n",
    "            'corrupted_prompt': full_corrupted\n",
    "        })\n",
    "        i += 1\n",
    "\n",
    "for j, template in enumerate(correct_prompt_templates):\n",
    "    i = 0\n",
    "    while i < number_examples_test:\n",
    "        a = random.randint(10, 99)\n",
    "        b = random.randint(10, 99)\n",
    "        c = random.randint(10, 99)\n",
    "        answer = a + b\n",
    "\n",
    "        prompt = template(a, b)\n",
    "        corrupted_prompt = template(a, c)\n",
    "        full_prompt = prefix_prompt + ' ' + prompt\n",
    "        full_corrupted = prefix_prompt + ' ' + corrupted_prompt\n",
    "\n",
    "        key = make_key(full_prompt, full_corrupted, answer)\n",
    "        if key in seen:\n",
    "            continue  # avoid duplicates across both sets\n",
    "        seen.add(key)\n",
    "\n",
    "        results_test.append({\n",
    "            'id': j,\n",
    "            'prompt': full_prompt,\n",
    "            'answer': answer,\n",
    "            'corrupted_prompt': full_corrupted\n",
    "        })\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0db66961",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids_set = set()\n",
    "for item in results_train:\n",
    "    if 'id' in item:\n",
    "        unique_ids_set.add(item['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b74a86bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "output_directory = 'datasets_csv/'\n",
    "\n",
    "for id in unique_ids_set:\n",
    "    data_train = [['clean', 'corrupted', 'answer']]\n",
    "    for item in results_train:\n",
    "        if id == item['id']:\n",
    "            data_train.append([item['prompt'],item['corrupted_prompt'], item['answer']])\n",
    "\n",
    "    data_test = [['clean', 'corrupted', 'answer']]\n",
    "    for item in results_test:\n",
    "        if id == item['id']:\n",
    "            data_test.append([item['prompt'],item['corrupted_prompt'], item['answer']])\n",
    "    \n",
    "    \n",
    "    subfolder = os.path.join(output_directory, f\"prompts_id_{id}\")\n",
    "    os.makedirs(subfolder, exist_ok=True)\n",
    "\n",
    "    filename_train = os.path.join(subfolder, \"train.csv\")\n",
    "    filename_test = os.path.join(subfolder, \"test.csv\")\n",
    "\n",
    "    with open(filename_train, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(data_train)\n",
    "\n",
    "    with open(filename_test, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "399ceb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 6000 training examples and 500 validation examples to datasets\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "number_examples_train = 6000\n",
    "number_examples_val = 500\n",
    "output_dir = Path(\"datasets\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Store data and deduplication keys\n",
    "train_data = []\n",
    "val_data = []\n",
    "seen = set()\n",
    "\n",
    "def make_key(prompt, corrupted, answer):\n",
    "    return (prompt, corrupted, answer)\n",
    "\n",
    "def generate_dataset(n, split_list):\n",
    "    count = 0\n",
    "    while count < n:\n",
    "        template = random.choice(correct_prompt_templates)\n",
    "        a = random.randint(10, 99)\n",
    "        b = random.randint(10, 99)\n",
    "        c = random.randint(10, 99)\n",
    "        answer = a + b\n",
    "\n",
    "        clean = f\"{prefix_prompt} {template(a, b)}\"\n",
    "        corrupted = f\"{prefix_prompt} {template(a, c)}\"\n",
    "\n",
    "        key = make_key(clean, corrupted, answer)\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "\n",
    "        split_list.append({\n",
    "            'prompt': clean,\n",
    "            'corrupted_prompt': corrupted,\n",
    "            'answer': answer\n",
    "        })\n",
    "        count += 1\n",
    "\n",
    "# Generate datasets\n",
    "generate_dataset(number_examples_train, train_data)\n",
    "generate_dataset(number_examples_val, val_data)\n",
    "\n",
    "# Shuffle\n",
    "random.shuffle(train_data)\n",
    "random.shuffle(val_data)\n",
    "\n",
    "# Save to CSVs\n",
    "def save_csv(data, filepath):\n",
    "    with open(filepath, \"w\", newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=['prompt', 'corrupted_prompt', 'answer'])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "\n",
    "save_csv(train_data, output_dir / \"train.csv\")\n",
    "save_csv(val_data, output_dir / \"validation.csv\")\n",
    "\n",
    "print(f\"Saved {len(train_data)} training examples and {len(val_data)} validation examples to {output_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
