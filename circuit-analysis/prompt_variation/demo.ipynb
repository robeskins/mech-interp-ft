{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fb67293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "424feffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import PreTrainedTokenizer, AutoTokenizer\n",
    "from transformer_lens import HookedTransformer\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "430f02c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eap.graph import Graph\n",
    "from eap.evaluate import evaluate_graph, evaluate_baseline\n",
    "from eap.attribute import attribute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d72ff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "def load_model(adapter_path, hf_model_name, translens_model_name, scratch_cache_dir = None):\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(hf_model_name, cache_dir=scratch_cache_dir)\n",
    "    model_with_lora = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "    model_with_lora = model_with_lora.merge_and_unload()\n",
    "    model = HookedTransformer.from_pretrained(model_name=translens_model_name, hf_model=model_with_lora, cache_dir=scratch_cache_dir)  \n",
    "\n",
    "    model.cfg.use_split_qkv_input = True\n",
    "    model.cfg.use_attn_result = True\n",
    "    model.cfg.use_hook_mlp_in = True\n",
    "    model.cfg.ungroup_grouped_query_attention = True\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e243c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_EAP(xs):\n",
    "    clean, corrupted, labels = zip(*xs)\n",
    "    clean = list(clean)\n",
    "    corrupted = list(corrupted)\n",
    "    return clean, corrupted, labels\n",
    "\n",
    "class EAPDataset(Dataset):\n",
    "    def __init__(self, filepath):\n",
    "        self.df = pd.read_csv(filepath)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def shuffle(self):\n",
    "        self.df = self.df.sample(frac=1)\n",
    "\n",
    "    def head(self, n: int):\n",
    "        self.df = self.df.head(n)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        return row['clean'], row['corrupted'], row['answer']\n",
    "    \n",
    "    def to_dataloader(self, batch_size: int):\n",
    "        return DataLoader(self, batch_size=batch_size, collate_fn=collate_EAP)\n",
    "    \n",
    "def get_logit_positions(logits: torch.Tensor, input_length: torch.Tensor):\n",
    "    batch_size = logits.size(0)\n",
    "    idx = torch.arange(batch_size, device=logits.device)\n",
    "\n",
    "    logits = logits[idx, input_length - 1]\n",
    "    return logits\n",
    "\n",
    "def kl_divergence(logits: torch.Tensor, clean_logits: torch.Tensor, input_length: torch.Tensor, labels: torch.Tensor, mean=True, loss=True):\n",
    "    logits = get_logit_positions(logits, input_length)\n",
    "    clean_logits = get_logit_positions(clean_logits, input_length)\n",
    "\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    clean_probs = torch.softmax(clean_logits, dim=-1)\n",
    "    results = F.kl_div(probs.log(), clean_probs.log(), log_target=True, reduction='none').mean(-1)\n",
    "    return results.mean() if mean else results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54fb14e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_faithfulness(model, g, dataloader, metric_fn):\n",
    "    baseline_performance = evaluate_baseline(model, dataloader, metric_fn).mean().item()\n",
    "    circuit_performance = evaluate_graph(model, g, dataloader, metric_fn,skip_clean=False).mean().item()\n",
    "    faithfulness = abs(baseline_performance - circuit_performance)\n",
    "    percentage_performance = (1 - faithfulness / baseline_performance) * 100\n",
    "\n",
    "    print(f\"Baseline performance: {baseline_performance}\")\n",
    "    print(f\"Circuit performance: {circuit_performance}\")\n",
    "    print(f\"Faithfulness: {faithfulness}\")\n",
    "    print(f\"Percentage of model performance achieved by the circuit: {percentage_performance:.2f}%\")\n",
    "\n",
    "    return faithfulness, percentage_performance\n",
    "\n",
    "def exact_match_accuracy(model, logits, corrupted_logits, input_lengths, labels):\n",
    "    batch_size = logits.size(0)\n",
    "    device = logits.device\n",
    "    positions = input_lengths - 1\n",
    "\n",
    "    last_logits = logits[torch.arange(batch_size), positions, :]\n",
    "    predicted_tokens = last_logits.argmax(dim=-1)\n",
    "    predicted_strings = [model.to_string(token.item()).strip() for token in predicted_tokens]\n",
    "\n",
    "    labels_strings = []\n",
    "    for i in range(batch_size):\n",
    "        lab = labels[i]\n",
    "        if isinstance(lab, torch.Tensor):\n",
    "            lab = lab.item()\n",
    "        labels_strings.append(str(lab).strip())\n",
    "\n",
    "    correct = []\n",
    "    for pred_str, label_str in zip(predicted_strings, labels_strings):\n",
    "        print(f'pred_str:{pred_str}, label_str:{label_str}')\n",
    "        if pred_str == label_str:\n",
    "            correct.append(1.0)\n",
    "        else:\n",
    "            correct.append(0.0)\n",
    "\n",
    "    return torch.tensor(correct, device=device)\n",
    "\n",
    "def calculate_accuracy(model, g, dataloader):\n",
    "    baseline_accuracy = evaluate_baseline(model, dataloader, partial(exact_match_accuracy, model)).mean().item()\n",
    "    graph_accuracy = evaluate_graph(model, g, dataloader, partial(exact_match_accuracy, model)).mean().item()   \n",
    "    return baseline_accuracy, graph_accuracy\n",
    "\n",
    "def exact_match_accuracy_diff(model, logits, corrupted_logits, input_lengths, labels, loss, mean):\n",
    "    batch_size = logits.size(0)\n",
    "    device = logits.device\n",
    "    positions = input_lengths - 1\n",
    "\n",
    "    # Helper to get predicted strings from logits\n",
    "    def get_predicted_strings(logits_tensor):\n",
    "        last_logits = logits_tensor[torch.arange(batch_size), positions, :]\n",
    "        predicted_tokens = last_logits.argmax(dim=-1)\n",
    "        return [model.to_string(token.item()).strip() for token in predicted_tokens]\n",
    "\n",
    "    # Get predicted strings for clean and corrupted\n",
    "    predicted_clean = get_predicted_strings(logits)\n",
    "    predicted_corrupted = get_predicted_strings(corrupted_logits)\n",
    "\n",
    "    # Convert labels to strings (same as your original)\n",
    "    labels_strings = []\n",
    "    for i in range(batch_size):\n",
    "        lab = labels[i]\n",
    "        if isinstance(lab, torch.Tensor):\n",
    "            lab = lab.item()\n",
    "        labels_strings.append(str(lab).strip())\n",
    "\n",
    "    # Compute exact match (1 or 0) for clean and corrupted\n",
    "    clean_correct = torch.tensor(\n",
    "        [1.0 if p == l else 0.0 for p, l in zip(predicted_clean, labels_strings)],\n",
    "        device=device\n",
    "    )\n",
    "    corrupted_correct = torch.tensor(\n",
    "        [1.0 if p == l else 0.0 for p, l in zip(predicted_corrupted, labels_strings)],\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Accuracy difference per example (corrupted - clean)\n",
    "    acc_diff = corrupted_correct - clean_correct\n",
    "\n",
    "    if mean:\n",
    "        return acc_diff.mean()\n",
    "    else:\n",
    "        return acc_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76a838fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-1.4B-deduped into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "scratch_cache_dir = \"/mnt/faster0/rje41/.cache/huggingface\"   \n",
    "hf_model_name = \"EleutherAI/pythia-1.4B-deduped\"\n",
    "translens_model_name=\"pythia-1.4B-deduped\"\n",
    "model = load_model(\n",
    "        adapter_path='../../initial-fine-tunng/add_sub_nlp/checkpoints/prompt_id_0/checkpoint-500',\n",
    "        hf_model_name=hf_model_name,\n",
    "        translens_model_name=translens_model_name,\n",
    "        scratch_cache_dir=scratch_cache_dir,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "151086d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/84 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "exact_match_accuracy_diff() missing 1 required positional argument: 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m dataloader = ds.to_dataloader(\u001b[32m6\u001b[39m)\n\u001b[32m      3\u001b[39m g = Graph.from_model(model)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mattribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexact_match_accuracy_diff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mEAP-IG-inputs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mig_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mech-interp-ft/.venv/lib/python3.12/site-packages/eap/attribute.py:439\u001b[39m, in \u001b[36mattribute\u001b[39m\u001b[34m(model, graph, dataloader, metric, method, intervention, aggregation, ig_steps, intervention_dataloader, quiet)\u001b[39m\n\u001b[32m    437\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m intervention != \u001b[33m'\u001b[39m\u001b[33mpatching\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    438\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mintervention must be \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpatching\u001b[39m\u001b[33m'\u001b[39m\u001b[33m for EAP-IG-inputs, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mintervention\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m     scores = \u001b[43mget_scores_eap_ig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mig_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m'\u001b[39m\u001b[33mclean-corrupted\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m intervention != \u001b[33m'\u001b[39m\u001b[33mpatching\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mech-interp-ft/.venv/lib/python3.12/site-packages/eap/attribute.py:161\u001b[39m, in \u001b[36mget_scores_eap_ig\u001b[39m\u001b[34m(model, graph, dataloader, metric, steps, quiet)\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m model.hooks(fwd_hooks=[(graph.nodes[\u001b[33m'\u001b[39m\u001b[33minput\u001b[39m\u001b[33m'\u001b[39m].out_hook, input_interpolation_hook(step))], bwd_hooks=bwd_hooks):\n\u001b[32m    160\u001b[39m     logits = model(clean_tokens, attention_mask=attention_mask)\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     metric_value = \u001b[43mmetric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch.isnan(metric_value).any().item():\n\u001b[32m    163\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMetric value is NaN\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: exact_match_accuracy_diff() missing 1 required positional argument: 'labels'"
     ]
    }
   ],
   "source": [
    "ds = EAPDataset(f'../../initial-fine-tunng/add_sub_nlp/datasets_csv/prompts_id_0/test.csv')\n",
    "dataloader = ds.to_dataloader(6)\n",
    "g = Graph.from_model(model)\n",
    "attribute(model, g, dataloader, partial(exact_match_accuracy_diff, loss=True, mean=True), method='EAP-IG-inputs', ig_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36077f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
