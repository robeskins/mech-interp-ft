{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8762cdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1fba2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eap.graph import Graph\n",
    "from eap.evaluate import evaluate_graph, evaluate_baseline\n",
    "from eap.attribute import attribute \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, PreTrainedTokenizer\n",
    "from peft import PeftModel\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformer_lens import HookedTransformer\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99af70c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(adapter_path, hf_model_name, translens_model_name, scratch_cache_dir = None):\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(hf_model_name, cache_dir=scratch_cache_dir)\n",
    "    model_with_lora = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "    model_with_lora = model_with_lora.merge_and_unload()\n",
    "    model = HookedTransformer.from_pretrained(model_name=translens_model_name, hf_model=model_with_lora, cache_dir=scratch_cache_dir)  \n",
    "\n",
    "    model.cfg.use_split_qkv_input = True\n",
    "    model.cfg.use_attn_result = True\n",
    "    model.cfg.use_hook_mlp_in = True\n",
    "    model.cfg.ungroup_grouped_query_attention = True\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53e3e159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_EAP(xs):\n",
    "    clean, corrupted, labels = zip(*xs)\n",
    "    clean = list(clean)\n",
    "    corrupted = list(corrupted)\n",
    "    return clean, corrupted, labels\n",
    "\n",
    "class EAPDataset(Dataset):\n",
    "    def __init__(self, filepath):\n",
    "        self.df = pd.read_csv(filepath)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def shuffle(self):\n",
    "        self.df = self.df.sample(frac=1)\n",
    "\n",
    "    def head(self, n: int):\n",
    "        self.df = self.df.head(n)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        return row['clean'], row['corrupted'], row['label']\n",
    "    \n",
    "    def to_dataloader(self, batch_size: int):\n",
    "        return DataLoader(self, batch_size=batch_size, collate_fn=collate_EAP)\n",
    "    \n",
    "def get_logit_positions(logits: torch.Tensor, input_length: torch.Tensor):\n",
    "    batch_size = logits.size(0)\n",
    "    idx = torch.arange(batch_size, device=logits.device)\n",
    "\n",
    "    logits = logits[idx, input_length - 1]\n",
    "    return logits\n",
    "\n",
    "def kl_divergence(logits: torch.Tensor, clean_logits: torch.Tensor, input_length: torch.Tensor, labels: torch.Tensor, mean=True, loss=True):\n",
    "    logits = get_logit_positions(logits, input_length)\n",
    "    clean_logits = get_logit_positions(clean_logits, input_length)\n",
    "\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    clean_probs = torch.softmax(clean_logits, dim=-1)\n",
    "    results = F.kl_div(probs.log(), clean_probs.log(), log_target=True, reduction='none').mean(-1)\n",
    "    return results.mean() if mean else results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df29a8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-1.4B-deduped into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "scratch_cache_dir = \"/mnt/fast0/rje41/.cache/huggingface\"    \n",
    "hf_model_name = \"EleutherAI/pythia-1.4B-deduped\"\n",
    "translens_model_name=\"pythia-1.4B-deduped\"\n",
    "adapter_path = \"../../fine-tuning/joint_training/checkpoints/add_sub/checkpoint-300\"\n",
    "model = load_model(\n",
    "        adapter_path=adapter_path,\n",
    "        hf_model_name=hf_model_name,\n",
    "        translens_model_name=translens_model_name,\n",
    "        scratch_cache_dir=scratch_cache_dir,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "859df5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = EAPDataset('../../datasets/Add_Sub_100_circuit.csv')\n",
    "dataloader = ds.to_dataloader(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "349830d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [05:09<00:00,  3.69s/it]\n"
     ]
    }
   ],
   "source": [
    "g = Graph.from_model(model)\n",
    "attribute(model, g, dataloader, partial(kl_divergence, loss=True, mean=True), method='EAP-IG-inputs', ig_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c512e85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_edges = len(g.edges)\n",
    "five_percent_edges = int(total_edges * 0.05)\n",
    "g.apply_greedy(five_percent_edges , absolute=True)\n",
    "g.to_json('add_sub_graph.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ead4e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_faithfulness(model, g, dataloader, metric_fn):\n",
    "    baseline_performance = evaluate_baseline(model, dataloader, metric_fn).mean().item()\n",
    "    circuit_performance = evaluate_graph(model, g, dataloader, metric_fn,skip_clean=False).mean().item()\n",
    "    faithfulness = abs(baseline_performance - circuit_performance)\n",
    "    percentage_performance = (1 - faithfulness / baseline_performance) * 100\n",
    "\n",
    "    print(f\"Baseline performance: {baseline_performance}\")\n",
    "    print(f\"Circuit performance: {circuit_performance}\")\n",
    "    print(f\"Faithfulness: {faithfulness}\")\n",
    "    print(f\"Percentage of model performance achieved by the circuit: {percentage_performance:.2f}%\")\n",
    "\n",
    "    return faithfulness, percentage_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a39a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [00:31<00:00,  2.71it/s]\n",
      "100%|██████████| 84/84 [00:55<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline performance: 0.0003849417844321579\n",
      "Circuit performance: 0.00031651731114834547\n",
      "Faithfulness: 6.84244732838124e-05\n",
      "Percentage of model performance achieved by the circuit: 82.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metric_fn = partial(kl_divergence, loss=False, mean=False)\n",
    "faithfulness, percentage_performance = calculate_faithfulness(model, g, dataloader, metric_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b12250c",
   "metadata": {},
   "source": [
    "### Mul_div circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24ce1126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-1.4B-deduped into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "scratch_cache_dir = \"/mnt/fast0/rje41/.cache/huggingface\"    \n",
    "hf_model_name = \"EleutherAI/pythia-1.4B-deduped\"\n",
    "translens_model_name=\"pythia-1.4B-deduped\"\n",
    "adapter_path = \"../../fine-tuning/joint_training/checkpoints/mul_div/checkpoint-300\"\n",
    "model = load_model(\n",
    "        adapter_path=adapter_path,\n",
    "        hf_model_name=hf_model_name,\n",
    "        translens_model_name=translens_model_name,\n",
    "        scratch_cache_dir=scratch_cache_dir,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46c8b431",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = EAPDataset('../../datasets/Mul_Div_circuit.csv')\n",
    "dataloader = ds.to_dataloader(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42aa7c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [05:10<00:00,  3.69s/it]\n"
     ]
    }
   ],
   "source": [
    "g_md = Graph.from_model(model)\n",
    "attribute(model, g_md, dataloader, partial(kl_divergence, loss=True, mean=True), method='EAP-IG-inputs', ig_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfcef2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_edges = len(g_md.edges)\n",
    "five_percent_edges = int(total_edges * 0.05)\n",
    "g_md.apply_greedy(five_percent_edges , absolute=True)\n",
    "g_md.to_json('mul_div_graph.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "481337a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [00:31<00:00,  2.70it/s]\n",
      "100%|██████████| 84/84 [00:55<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline performance: 0.0003781667910516262\n",
      "Circuit performance: 0.00033664467628113925\n",
      "Faithfulness: 4.152211477048695e-05\n",
      "Percentage of model performance achieved by the circuit: 89.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metric_fn = partial(kl_divergence, loss=False, mean=False)\n",
    "faithfulness, percentage_performance = calculate_faithfulness(model, g_md, dataloader, metric_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7352c10b",
   "metadata": {},
   "source": [
    "### Merged circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4adfce94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-1.4B-deduped into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "scratch_cache_dir = \"/mnt/fast0/rje41/.cache/huggingface\"    \n",
    "hf_model_name = \"EleutherAI/pythia-1.4B-deduped\"\n",
    "translens_model_name=\"pythia-1.4B-deduped\"\n",
    "adapter_path = \"../../fine-tuning/joint_training/checkpoints/merged/checkpoint-300\"\n",
    "model = load_model(\n",
    "        adapter_path=adapter_path,\n",
    "        hf_model_name=hf_model_name,\n",
    "        translens_model_name=translens_model_name,\n",
    "        scratch_cache_dir=scratch_cache_dir,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb25fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = EAPDataset('../../datasets/Add_Sub_100_circuit.csv')\n",
    "dataloader = ds.to_dataloader(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3098803f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [05:11<00:00,  3.70s/it]\n"
     ]
    }
   ],
   "source": [
    "g_merge = Graph.from_model(model)\n",
    "attribute(model, g_merge, dataloader, partial(kl_divergence, loss=True, mean=True), method='EAP-IG-inputs', ig_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2daf105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_edges = len(g_merge.edges)\n",
    "five_percent_edges = int(total_edges * 0.05)\n",
    "g_merge.apply_greedy(five_percent_edges , absolute=True)\n",
    "g_merge.to_json('add_sub_merge_graph.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b76cb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [00:30<00:00,  2.74it/s]\n",
      "100%|██████████| 84/84 [00:55<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline performance: 0.00038985011633485556\n",
      "Circuit performance: 0.0003385224554222077\n",
      "Faithfulness: 5.132766091264784e-05\n",
      "Percentage of model performance achieved by the circuit: 86.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metric_fn = partial(kl_divergence, loss=False, mean=False)\n",
    "faithfulness, percentage_performance = calculate_faithfulness(model, g_merge, dataloader, metric_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
