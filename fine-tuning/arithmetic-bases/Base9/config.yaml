model_name: "EleutherAI/pythia-1.4B-deduped"
scratch_cache_dir: "/mnt/faster0/rje41/.cache/huggingface"
dataset_path: 'arithmetic-bases/Base9/datasets_csv'
max_length_strings: 32

training_args:
  per_device_train_batch_size: 8
  gradient_accumulation_steps: 4
  weight_decay: 0.01
  logging_dir: "./logs"
  logging_steps: 10
  save_steps: 200
  save_strategy: "steps"
  fp16: true
  report_to: "none"
  learning_rate: 3e-4
  max_steps: 1000

lora_config:
  r: 64
  alpha: 128

  