{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fb67293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "424feffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import PreTrainedTokenizer, AutoTokenizer\n",
    "from transformer_lens import HookedTransformer\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "430f02c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eap.graph import Graph\n",
    "from eap.evaluate import evaluate_graph, evaluate_baseline\n",
    "from eap.attribute import attribute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d72ff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "def load_model(adapter_path, hf_model_name, translens_model_name, scratch_cache_dir = None):\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(hf_model_name, cache_dir=scratch_cache_dir)\n",
    "    model_with_lora = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "    model_with_lora = model_with_lora.merge_and_unload()\n",
    "    model = HookedTransformer.from_pretrained(model_name=translens_model_name, hf_model=model_with_lora, cache_dir=scratch_cache_dir)  \n",
    "\n",
    "    model.cfg.use_split_qkv_input = True\n",
    "    model.cfg.use_attn_result = True\n",
    "    model.cfg.use_hook_mlp_in = True\n",
    "    model.cfg.ungroup_grouped_query_attention = True\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e243c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_EAP(xs):\n",
    "    clean, corrupted, labels = zip(*xs)\n",
    "    clean = list(clean)\n",
    "    corrupted = list(corrupted)\n",
    "    return clean, corrupted, labels\n",
    "\n",
    "class EAPDataset(Dataset):\n",
    "    def __init__(self, filepath):\n",
    "        self.df = pd.read_csv(filepath)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def shuffle(self):\n",
    "        self.df = self.df.sample(frac=1)\n",
    "\n",
    "    def head(self, n: int):\n",
    "        self.df = self.df.head(n)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        return row['clean'], row['corrupted'], row['answer']\n",
    "    \n",
    "    def to_dataloader(self, batch_size: int):\n",
    "        return DataLoader(self, batch_size=batch_size, collate_fn=collate_EAP)\n",
    "    \n",
    "def get_logit_positions(logits: torch.Tensor, input_length: torch.Tensor):\n",
    "    batch_size = logits.size(0)\n",
    "    idx = torch.arange(batch_size, device=logits.device)\n",
    "\n",
    "    logits = logits[idx, input_length - 1]\n",
    "    return logits\n",
    "\n",
    "def kl_divergence(logits: torch.Tensor, clean_logits: torch.Tensor, input_length: torch.Tensor, labels: torch.Tensor, mean=True, loss=True):\n",
    "    logits = get_logit_positions(logits, input_length)\n",
    "    clean_logits = get_logit_positions(clean_logits, input_length)\n",
    "\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    clean_probs = torch.softmax(clean_logits, dim=-1)\n",
    "    results = F.kl_div(probs.log(), clean_probs.log(), log_target=True, reduction='none').mean(-1)\n",
    "    return results.mean() if mean else results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3e2e08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-1.4B-deduped into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "scratch_cache_dir = \"/mnt/faster0/rje41/.cache/huggingface\"    \n",
    "hf_model_name = \"EleutherAI/pythia-1.4B-deduped\"\n",
    "translens_model_name=\"pythia-1.4B-deduped\"\n",
    "adapter_path = \"two-digit-arithmetic/reverse_addition/checkpoints/checkpoint-500\"\n",
    "model = load_model(\n",
    "        adapter_path=adapter_path,\n",
    "        hf_model_name=hf_model_name,\n",
    "        translens_model_name=translens_model_name,\n",
    "        scratch_cache_dir=scratch_cache_dir,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "141a9004",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = EAPDataset('two-digit-arithmetic/reverse_addition/datasets_csv/validation.csv')\n",
    "dataloader = ds.to_dataloader(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f1913b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:40<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def exact_match_accuracy(model, logits, corrupted_logits, input_lengths, labels):\n",
    "    batch_size = logits.size(0)\n",
    "    device = logits.device\n",
    "    positions = input_lengths - 1\n",
    "\n",
    "    last_logits = logits[torch.arange(batch_size), positions, :]\n",
    "    predicted_tokens = last_logits.argmax(dim=-1)\n",
    "    predicted_strings = [model.to_string(token.item()).strip() for token in predicted_tokens]\n",
    "\n",
    "    labels_strings = []\n",
    "    for i in range(batch_size):\n",
    "        lab = labels[i]\n",
    "        if isinstance(lab, torch.Tensor):\n",
    "            lab = lab.item()\n",
    "        labels_strings.append(str(lab).strip())\n",
    "\n",
    "    correct = []\n",
    "    for pred_str, label_str in zip(predicted_strings, labels_strings):\n",
    "        # print(f'Pred_str: {pred_str}, label_str: {label_str}')\n",
    "        if pred_str == label_str:\n",
    "            correct.append(1.0)\n",
    "        else:\n",
    "            correct.append(0.0)\n",
    "\n",
    "    return torch.tensor(correct, device=device)\n",
    "\n",
    "def calculate_accuracy(model, g, dataloader):\n",
    "    baseline_accuracy = evaluate_baseline(model, dataloader, partial(exact_match_accuracy, model)).mean().item()\n",
    "    graph_accuracy = evaluate_graph(model, g, dataloader, partial(exact_match_accuracy, model)).mean().item()   \n",
    "    return baseline_accuracy, graph_accuracy\n",
    "\n",
    "baseline_accuracy = evaluate_baseline(model, dataloader, partial(exact_match_accuracy, model)).mean().item()\n",
    "print(baseline_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
