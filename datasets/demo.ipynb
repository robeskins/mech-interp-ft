{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fb67293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "424feffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import PreTrainedTokenizer, AutoTokenizer\n",
    "from transformer_lens import HookedTransformer\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "430f02c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eap.graph import Graph\n",
    "from eap.evaluate import evaluate_graph, evaluate_baseline\n",
    "from eap.attribute import attribute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d72ff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "def load_adapter_into_hooked_transformer(adapter_path, \n",
    "                                         hf_model_name, \n",
    "                                         translens_model_name, \n",
    "                                         adapter = True, \n",
    "                                         scratch_cache_dir = None):\n",
    "    if adapter == True: \n",
    "        base_model = AutoModelForCausalLM.from_pretrained(hf_model_name, cache_dir=scratch_cache_dir)\n",
    "        model_with_lora = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "        adapter_model = model_with_lora.merge_and_unload()\n",
    "        model = HookedTransformer.from_pretrained(model_name=translens_model_name, hf_model=adapter_model, cache_dir=scratch_cache_dir)  \n",
    "    else:\n",
    "        model = HookedTransformer.from_pretrained(model_name=translens_model_name, cache_dir=scratch_cache_dir)  \n",
    "\n",
    "    model.cfg.use_split_qkv_input = True\n",
    "    model.cfg.use_attn_result = True\n",
    "    model.cfg.use_hook_mlp_in = True\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e243c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_EAP(xs):\n",
    "    clean, corrupted, labels = zip(*xs)\n",
    "    clean = list(clean)\n",
    "    corrupted = list(corrupted)\n",
    "    return clean, corrupted, labels\n",
    "\n",
    "class EAPDataset(Dataset):\n",
    "    def __init__(self, filepath):\n",
    "        self.df = pd.read_csv(filepath)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def shuffle(self):\n",
    "        self.df = self.df.sample(frac=1)\n",
    "\n",
    "    def head(self, n: int):\n",
    "        self.df = self.df.head(n)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        return row['clean'], row['corrupted'], row['label']\n",
    "    \n",
    "    def to_dataloader(self, batch_size: int):\n",
    "        return DataLoader(self, batch_size=batch_size, collate_fn=collate_EAP)\n",
    "    \n",
    "def get_logit_positions(logits: torch.Tensor, input_length: torch.Tensor):\n",
    "    batch_size = logits.size(0)\n",
    "    idx = torch.arange(batch_size, device=logits.device)\n",
    "\n",
    "    logits = logits[idx, input_length - 1]\n",
    "    return logits\n",
    "\n",
    "def kl_divergence(logits: torch.Tensor, clean_logits: torch.Tensor, input_length: torch.Tensor, labels: torch.Tensor, mean=True, loss=True):\n",
    "    logits = get_logit_positions(logits, input_length)\n",
    "    clean_logits = get_logit_positions(clean_logits, input_length)\n",
    "\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    clean_probs = torch.softmax(clean_logits, dim=-1)\n",
    "    results = F.kl_div(probs.log(), clean_probs.log(), log_target=True, reduction='none').mean(-1)\n",
    "    return results.mean() if mean else results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3e2e08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-1.4B-deduped into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "scratch_cache_dir = \"/mnt/faster0/rje41/.cache/huggingface\"    \n",
    "hf_model_name = \"EleutherAI/pythia-1.4B-deduped\"\n",
    "translens_model_name=\"pythia-1.4B-deduped\"\n",
    "adapter_path = \"/homes/rje41/mech-interp-ft/circuit-analysis/prompt_variation/results/checkpoint-300/prompt_template_0/graph.json\"\n",
    "model = load_adapter_into_hooked_transformer(\n",
    "        adapter_path=None,\n",
    "        hf_model_name=hf_model_name,\n",
    "        translens_model_name=translens_model_name,\n",
    "        scratch_cache_dir=scratch_cache_dir,\n",
    "        adapter = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "141a9004",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = EAPDataset('AddSub_corrupt_swap/datasets_csv/Add_Sub_100_ft (2).csv')\n",
    "dataloader = ds.to_dataloader(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0aa0ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/750 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacity of 23.57 GiB of which 1.46 GiB is free. Process 2507595 has 2.06 GiB memory in use. Process 2856799 has 4.32 GiB memory in use. Including non-PyTorch memory, this process has 15.71 GiB memory in use. Of the allocated memory 15.02 GiB is allocated by PyTorch, and 390.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results.mean() \u001b[38;5;28;01mif\u001b[39;00m mean \u001b[38;5;28;01melse\u001b[39;00m results\n\u001b[32m      9\u001b[39m g = Graph.from_model(model)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mattribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkl_divergence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mEAP-IG-inputs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mig_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mech-interp-ft/.venv/lib/python3.12/site-packages/eap/attribute.py:439\u001b[39m, in \u001b[36mattribute\u001b[39m\u001b[34m(model, graph, dataloader, metric, method, intervention, aggregation, ig_steps, intervention_dataloader, quiet)\u001b[39m\n\u001b[32m    437\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m intervention != \u001b[33m'\u001b[39m\u001b[33mpatching\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    438\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mintervention must be \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpatching\u001b[39m\u001b[33m'\u001b[39m\u001b[33m for EAP-IG-inputs, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mintervention\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m     scores = \u001b[43mget_scores_eap_ig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mig_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m'\u001b[39m\u001b[33mclean-corrupted\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m intervention != \u001b[33m'\u001b[39m\u001b[33mpatching\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mech-interp-ft/.venv/lib/python3.12/site-packages/eap/attribute.py:169\u001b[39m, in \u001b[36mget_scores_eap_ig\u001b[39m\u001b[34m(model, graph, dataloader, metric, steps, quiet)\u001b[39m\n\u001b[32m    167\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMetric: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    168\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mMetric value is NaN\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m     \u001b[43mmetric_value\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.isnan(scores).any().item():\n\u001b[32m    172\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMetric value is NaN\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mech-interp-ft/.venv/lib/python3.12/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mech-interp-ft/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mech-interp-ft/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 1.88 GiB. GPU 0 has a total capacity of 23.57 GiB of which 1.46 GiB is free. Process 2507595 has 2.06 GiB memory in use. Process 2856799 has 4.32 GiB memory in use. Including non-PyTorch memory, this process has 15.71 GiB memory in use. Of the allocated memory 15.02 GiB is allocated by PyTorch, and 390.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "def kl_divergence(logits: torch.Tensor, clean_logits: torch.Tensor, input_length: torch.Tensor, labels: torch.Tensor, mean=True, loss=True):\n",
    "    logits = get_logit_positions(logits, input_length)\n",
    "    clean_logits = get_logit_positions(clean_logits, input_length)\n",
    "\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    clean_probs = torch.softmax(clean_logits, dim=-1)\n",
    "    results = F.kl_div(probs.log(), clean_probs.log(), log_target=True, reduction='none').mean(-1)\n",
    "    return results.mean() if mean else results\n",
    "g = Graph.from_model(model)\n",
    "attribute(model, g, dataloader, partial(kl_divergence, loss=True, mean=True), method='EAP-IG-inputs', ig_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe1f68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_faithfulness(model, g, dataloader, metric_fn):\n",
    "    baseline_performance = evaluate_baseline(model, dataloader, metric_fn).mean().item()\n",
    "    circuit_performance = evaluate_graph(model, g, dataloader, metric_fn,skip_clean=False).mean().item()\n",
    "    faithfulness = abs(baseline_performance - circuit_performance)\n",
    "    percentage_performance = (1 - faithfulness / baseline_performance) * 100\n",
    "\n",
    "    print(f\"Baseline performance: {baseline_performance}\")\n",
    "    print(f\"Circuit performance: {circuit_performance}\")\n",
    "    print(f\"Faithfulness: {faithfulness}\")\n",
    "    print(f\"Percentage of model performance achieved by the circuit: {percentage_performance:.2f}%\")\n",
    "\n",
    "    return baseline_performance, circuit_performance, faithfulness, percentage_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064a5d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned the graph!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [00:57<00:00,  2.91it/s]\n",
      "100%|██████████| 167/167 [01:41<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline performance: 3.4469907404854894e-05\n",
      "Circuit performance: 2.936303280876018e-05\n",
      "Faithfulness: 5.106874596094713e-06\n",
      "Percentage of model performance achieved by the circuit: 85.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_edges = len(g.edges)\n",
    "percent_edges = int(total_edges * 0.05)\n",
    "g.apply_topn(percent_edges , absolute=True, prune=True)\n",
    "print('Pruned the graph!')\n",
    "\n",
    "metric_fn = partial(kl_divergence, loss=False, mean=False)\n",
    "baseline_performance, circuit_performance, faithfulness, percentage_performance = calculate_faithfulness(model, g, dataloader, metric_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
